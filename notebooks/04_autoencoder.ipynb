{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "14fcffbc",
            "metadata": {},
            "source": [
                "# 04. Convolutional Autoencoder (Unsupervised)\n",
                "\n",
                "## Introduction\n",
                "This notebook implements a Convolutional Autoencoder (CAE) for unsupervised anomaly detection.\n",
                "The model is trained ONLY on normal images to learn to reconstruct them.\n",
                "Anomalies are detected by high reconstruction error.\n",
                "\n",
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cfa73889",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras import layers, models\n",
                "\n",
                "tf.random.set_seed(42)\n",
                "np.random.seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fb76c98b",
            "metadata": {},
            "source": [
                "## 1. Data Loading\n",
                "For the Autoencoder, we train ONLY on the 'train/good' folder."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "beee0df6",
            "metadata": {},
            "outputs": [],
            "source": [
                "IMG_SIZE = (256, 256)\n",
                "BATCH_SIZE = 16\n",
                "DATA_DIR = \"../data/raw\"\n",
                "TARGET_CATEGORY = 'bottle'\n",
                "TRAIN_DIR = os.path.join(DATA_DIR, TARGET_CATEGORY, 'train')\n",
                "TEST_DIR = os.path.join(DATA_DIR, TARGET_CATEGORY, 'test')\n",
                "\n",
                "# Load only normal images for training\n",
                "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
                "    TRAIN_DIR,\n",
                "    label_mode=None, # No labels needed for Autoencoder\n",
                "    image_size=IMG_SIZE,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    seed=123\n",
                ")\n",
                "\n",
                "# Preprocessing: Rescale to [0, 1]\n",
                "def preprocess(image):\n",
                "    return tf.cast(image, tf.float32) / 255.0\n",
                "\n",
                "train_ds = train_ds.map(preprocess).cache().shuffle(1000).prefetch(tf.data.AUTOTUNE)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "931cff80",
            "metadata": {},
            "source": [
                "## 2. Model Architecture\n",
                "Encoder-Decoder architecture."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c95bdcb6",
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_autoencoder(input_shape):\n",
                "    # Encoder\n",
                "    inputs = layers.Input(shape=input_shape)\n",
                "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same', strides=2)(inputs)\n",
                "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', strides=2)(x)\n",
                "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', strides=2)(x)\n",
                "    \n",
                "    # Latent space\n",
                "    shape_before_flattening = tf.keras.backend.int_shape(x)[1:]\n",
                "    x = layers.Flatten()(x)\n",
                "    latent = layers.Dense(128, name='latent_vector')(x)\n",
                "    \n",
                "    # Decoder\n",
                "    x = layers.Dense(np.prod(shape_before_flattening))(latent)\n",
                "    x = layers.Reshape(shape_before_flattening)(x)\n",
                "    \n",
                "    x = layers.Conv2DTranspose(128, (3, 3), activation='relu', padding='same', strides=2)(x)\n",
                "    x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same', strides=2)(x)\n",
                "    x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same', strides=2)(x)\n",
                "    \n",
                "    outputs = layers.Conv2DTranspose(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
                "    \n",
                "    model = models.Model(inputs, outputs, name='autoencoder')\n",
                "    return model\n",
                "\n",
                "autoencoder = create_autoencoder(IMG_SIZE + (3,))\n",
                "autoencoder.summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b28e0cfc",
            "metadata": {},
            "source": [
                "## 3. Training\n",
                "Loss function is Mean Squared Error (MSE) between input and output."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "978ac196",
            "metadata": {},
            "outputs": [],
            "source": [
                "autoencoder.compile(optimizer='adam', loss='mse')\n",
                "\n",
                "history = autoencoder.fit(\n",
                "    train_ds,\n",
                "    epochs=20,\n",
                "    # In unsupervised setting, we often use a split of train set as validation,\n",
                "    # or just monitor loss.\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "17b6c377",
            "metadata": {},
            "source": [
                "## 4. Anomaly Detection\n",
                "We test on the test set (containing both normal and anomalies) and calculate reconstruction error."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "15e236d4",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load Test Data\n",
                "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
                "    TEST_DIR,\n",
                "    label_mode='int',\n",
                "    image_size=IMG_SIZE,\n",
                "    batch_size=1,\n",
                "    shuffle=False\n",
                ")\n",
                "\n",
                "def predict_anomaly(model, dataset, threshold=None):\n",
                "    reconstruction_errors = []\n",
                "    labels = []\n",
                "    \n",
                "    for image, label in dataset:\n",
                "        image = preprocess(image)\n",
                "        reconstructed = model.predict(image, verbose=0)\n",
                "        loss = np.mean(np.abs(image - reconstructed))\n",
                "        reconstruction_errors.append(loss)\n",
                "        labels.append(label.numpy()[0])\n",
                "        \n",
                "    return np.array(reconstruction_errors), np.array(labels)\n",
                "\n",
                "errors, labels = predict_anomaly(autoencoder, test_ds)\n",
                "\n",
                "# Determine threshold (e.g., 95th percentile of errors)\n",
                "# Ideally this is done on a validation set of normal images\n",
                "threshold = np.percentile(errors, 90)\n",
                "print(f\"Threshold: {threshold}\")\n",
                "\n",
                "# Visualize\n",
                "plt.figure(figsize=(10, 5))\n",
                "plt.hist(errors[labels==0], bins=20, alpha=0.5, label='Normal')\n",
                "plt.hist(errors[labels!=0], bins=20, alpha=0.5, label='Anomaly')\n",
                "plt.axvline(threshold, color='r', linestyle='--', label='Threshold')\n",
                "plt.legend()\n",
                "plt.title(\"Reconstruction Error Distribution\")\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
