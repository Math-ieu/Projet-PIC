{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "14fcffbc",
            "metadata": {},
            "source": [
                "# 04. Convolutional Autoencoder (Unsupervised)\n",
                "\n",
                "## Introduction\n",
                "This notebook implements a Convolutional Autoencoder (CAE) for unsupervised anomaly detection.\n",
                "The model is trained ONLY on normal images to learn to reconstruct them.\n",
                "Anomalies are detected by high reconstruction error.\n",
                "\n",
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cfa73889",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras import layers, models\n",
                "\n",
                "tf.random.set_seed(42)\n",
                "np.random.seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fb76c98b",
            "metadata": {},
            "source": [
                "## 1. Data Loading\n",
                "For the Autoencoder, we train ONLY on the 'train/good' folder."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "beee0df6",
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "import glob\n",
                "import pandas as pd\n",
                "import random\n",
                "import shutil\n",
                "import logging\n",
                "import json\n",
                "import numpy as np\n",
                "import tensorflow as tf\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix\n",
                "from skimage import measure\n",
                "\n",
                "# --- Inlined from src.evaluation.metrics ---\n",
                "\n",
                "def get_metrics():\n",
                "    \"\"\"\n",
                "    Returns a list of Keras metrics.\n",
                "    \"\"\"\n",
                "    return [\n",
                "        tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy'),\n",
                "    ]\n",
                "\n",
                "def calculate_auc(y_true, y_pred):\n",
                "    \"\"\"\n",
                "    Calculate AUC-ROC score.\n",
                "    \"\"\"\n",
                "    # For multi-class, we might need one-vs-rest\n",
                "    if len(np.unique(y_true)) > 2:\n",
                "        return roc_auc_score(y_true, y_pred, multi_class='ovr')\n",
                "    return roc_auc_score(y_true, y_pred)\n",
                "\n",
                "def calculate_f1(y_true, y_pred_classes):\n",
                "    \"\"\"\n",
                "    Calculate F1 score.\n",
                "    \"\"\"\n",
                "    return f1_score(y_true, y_pred_classes, average='macro')\n",
                "\n",
                "def get_confusion_matrix(y_true, y_pred_classes):\n",
                "    \"\"\"\n",
                "    Calculate confusion matrix.\n",
                "    \"\"\"\n",
                "    return confusion_matrix(y_true, y_pred_classes)\n",
                "\n",
                "def calculate_iou(y_true, y_pred, threshold=0.5):\n",
                "    \"\"\"\n",
                "    Calculate Intersection over Union (IoU) for segmentation masks.\n",
                "    y_true: Ground truth masks (0 or 1)\n",
                "    y_pred: Predicted anomaly maps (0 to 1)\n",
                "    \"\"\"\n",
                "    y_pred_bin = (y_pred > threshold).astype(int)\n",
                "    y_true = y_true.astype(int)\n",
                "    \n",
                "    intersection = np.logical_and(y_true, y_pred_bin).sum()\n",
                "    union = np.logical_or(y_true, y_pred_bin).sum()\n",
                "    \n",
                "    if union == 0:\n",
                "        return 1.0 if intersection == 0 else 0.0\n",
                "        \n",
                "    return intersection / union\n",
                "\n",
                "def calculate_pro(y_true, y_pred, threshold=0.5):\n",
                "    \"\"\"\n",
                "    Calculate Per-Region Overlap (PRO).\n",
                "    Average coverage of each connected component in ground truth.\n",
                "    \"\"\"\n",
                "    y_pred_bin = (y_pred > threshold).astype(int)\n",
                "    y_true = y_true.astype(int)\n",
                "    \n",
                "    # Label connected components in ground truth\n",
                "    labeled_gt, num_features = measure.label(y_true, return_num=True, connectivity=2)\n",
                "    \n",
                "    if num_features == 0:\n",
                "        # No anomalies in ground truth\n",
                "        # If prediction is also empty, perfect. If prediction has noise, it's a false positive.\n",
                "        # PRO is typically defined on anomalous regions. \n",
                "        # We return 1.0 if no anomalies exist (perfect coverage of \"nothing\").\n",
                "        return 1.0\n",
                "        \n",
                "    pro_scores = []\n",
                "    for region_idx in range(1, num_features + 1):\n",
                "        region_mask = (labeled_gt == region_idx)\n",
                "        region_area = region_mask.sum()\n",
                "        \n",
                "        # Intersection of prediction with this region\n",
                "        intersection = np.logical_and(region_mask, y_pred_bin).sum()\n",
                "        \n",
                "        coverage = intersection / region_area\n",
                "        pro_scores.append(coverage)\n",
                "        \n",
                "    return np.mean(pro_scores)\n",
                "\n",
                "# --- Inlined from src.evaluation.benchmark ---\n",
                "\n",
                "logger = logging.getLogger(__name__)\n",
                "\n",
                "def evaluate_model(model, test_dataset, test_masks=None):\n",
                "    \"\"\"\n",
                "    Evaluates a model on the test dataset.\n",
                "    \"\"\"\n",
                "    logger.info(\"Evaluating model...\")\n",
                "    results = model.evaluate(test_dataset, return_dict=True)\n",
                "    \n",
                "    # Get predictions for advanced metrics\n",
                "    y_true = []\n",
                "    y_pred = []\n",
                "    \n",
                "    for images, labels in test_dataset:\n",
                "        preds = model.predict(images, verbose=0)\n",
                "        y_true.extend(labels.numpy())\n",
                "        y_pred.extend(preds)\n",
                "        \n",
                "    y_true = np.array(y_true)\n",
                "    y_pred = np.array(y_pred)\n",
                "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
                "    \n",
                "    # Calculate additional metrics\n",
                "    try:\n",
                "        auc = calculate_auc(y_true, y_pred) # Might fail if only one class in batch\n",
                "        f1 = calculate_f1(y_true, y_pred_classes)\n",
                "        results['auc'] = auc\n",
                "        results['f1'] = f1\n",
                "        \n",
                "        if test_masks is not None:\n",
                "            # Assuming test_masks matches y_pred order\n",
                "            # We need to ensure y_pred is in the same shape/format as masks if they are images\n",
                "            # But y_pred from classification model is (N, num_classes) or (N, 1)\n",
                "            # IoU/PRO require segmentation maps (N, H, W, 1)\n",
                "            # If the model is an Autoencoder, we might generate maps.\n",
                "            # If it's a classifier, IoU/PRO don't make sense unless we have CAM/GradCAM.\n",
                "            \n",
                "            # For now, we only calculate if we have compatible shapes\n",
                "            if len(y_pred.shape) == 4 and len(test_masks.shape) == 4:\n",
                "                 iou = calculate_iou(test_masks, y_pred)\n",
                "                 pro = calculate_pro(test_masks, y_pred)\n",
                "                 results['iou'] = iou\n",
                "                 results['pro'] = pro\n",
                "            else:\n",
                "                logger.warning(\"Skipping IoU/PRO: Predictions or masks shape mismatch for segmentation.\")\n",
                "    except Exception as e:\n",
                "        logger.warning(f\"Could not calculate advanced metrics: {e}\")\n",
                "        \n",
                "    return results\n",
                "\n",
                "def compare_models(models_dict, test_dataset):\n",
                "    \"\"\"\n",
                "    Compares multiple models.\n",
                "    \"\"\"\n",
                "    comparison = {}\n",
                "    for name, model in models_dict.items():\n",
                "        logger.info(f\"Benchmarking {name}...\")\n",
                "        comparison[name] = evaluate_model(model, test_dataset)\n",
                "        \n",
                "    return comparison\n",
                "\n",
                "# --- Inlined from src.preprocessing.dataset ---\n",
                "\n",
                "def augment_image(image_path, save_dir, prefix, count):\n",
                "    \"\"\"\n",
                "    Reads an image, applies random augmentations, and saves it.\n",
                "    \"\"\"\n",
                "    try:\n",
                "        img = tf.io.read_file(image_path)\n",
                "        img = tf.image.decode_png(img, channels=3)\n",
                "        \n",
                "        # Random augmentations\n",
                "        img = tf.image.random_flip_left_right(img)\n",
                "        img = tf.image.random_flip_up_down(img)\n",
                "        img = tf.image.random_brightness(img, max_delta=0.2)\n",
                "        img = tf.image.random_contrast(img, lower=0.8, upper=1.2)\n",
                "        \n",
                "        # Ensure valid range [0, 255]\n",
                "        img = tf.clip_by_value(img, 0, 255)\n",
                "        img = tf.cast(img, tf.uint8)\n",
                "        \n",
                "        encoded_img = tf.image.encode_png(img)\n",
                "        \n",
                "        filename = f\"{prefix}_{count}.png\"\n",
                "        save_path = os.path.join(save_dir, filename)\n",
                "        \n",
                "        tf.io.write_file(save_path, encoded_img)\n",
                "        return save_path\n",
                "    except Exception as e:\n",
                "        logger.warning(f\"Failed to augment image {image_path}: {e}\")\n",
                "        return None\n",
                "\n",
                "def balance_classes(df, target_count=1000, save_root=\"data/processed/augmented\"):\n",
                "    \"\"\"\n",
                "    Balances classes in the DataFrame by augmenting rare classes to reach target_count.\n",
                "    \"\"\"\n",
                "    if df.empty:\n",
                "        return df\n",
                "        \n",
                "    logger.info(f\"Balancing classes to target count: {target_count}...\")\n",
                "    \n",
                "    # Create augmentation directory\n",
                "    if os.path.exists(save_root):\n",
                "        # Optional: Clear previous augmentations to avoid staleness, \n",
                "        # but might be slow if we re-run often. For now, let's keep it simple and overwrite/add.\n",
                "        pass\n",
                "    else:\n",
                "        os.makedirs(save_root, exist_ok=True)\n",
                "        \n",
                "    new_rows = []\n",
                "    \n",
                "    # Group by label (which maps to a specific Category_DefectType)\n",
                "    # We need to know the label_str to name files appropriately\n",
                "    unique_labels = df['label'].unique()\n",
                "    \n",
                "    for label in unique_labels:\n",
                "        class_subset = df[df['label'] == label]\n",
                "        current_count = len(class_subset)\n",
                "        \n",
                "        if current_count >= target_count:\n",
                "            continue\n",
                "            \n",
                "        needed = target_count - current_count\n",
                "        label_str = class_subset.iloc[0]['label_str']\n",
                "        category = class_subset.iloc[0]['category']\n",
                "        \n",
                "        logger.info(f\"Augmenting class '{label_str}': {current_count} -> {target_count} (+{needed})\")\n",
                "        \n",
                "        # Create class specific save dir\n",
                "        class_save_dir = os.path.join(save_root, label_str)\n",
                "        os.makedirs(class_save_dir, exist_ok=True)\n",
                "        \n",
                "        # Source images to augment\n",
                "        source_images = class_subset['filepath'].tolist()\n",
                "        \n",
                "        for i in range(needed):\n",
                "            # Randomly select a source image\n",
                "            src_img = random.choice(source_images)\n",
                "            \n",
                "            # Augment and save\n",
                "            new_path = augment_image(src_img, class_save_dir, \"aug\", i)\n",
                "            \n",
                "            if new_path:\n",
                "                new_rows.append({\n",
                "                    'filepath': new_path,\n",
                "                    'category': category,\n",
                "                    'label': label,\n",
                "                    'label_str': label_str\n",
                "                })\n",
                "                \n",
                "    if new_rows:\n",
                "        augmented_df = pd.DataFrame(new_rows)\n",
                "        df = pd.concat([df, augmented_df], ignore_index=True)\n",
                "        \n",
                "    logger.info(f\"Balancing complete. Total samples: {len(df)}\")\n",
                "    return df\n",
                "\n",
                "def load_and_split_data(data_dir, split_ratios=(0.8, 0.1, 0.1), seed=42, target_category=None, augment=False):\n",
                "    \"\"\"\n",
                "    Load MVTec AD data, merge normal and abnormal, and split into train/val/test.\n",
                "    Assigns unique labels for each (Category, DefectType) pair.\n",
                "    \n",
                "    Args:\n",
                "        data_dir (str): Path to the root of the MVTec AD dataset (containing category folders).\n",
                "        split_ratios (tuple): (train_ratio, val_ratio, test_ratio). Must sum to 1.\n",
                "        seed (int): Random seed for reproducibility.\n",
                "        target_category (str, optional): If provided, only load data for this specific category.\n",
                "        augment (bool): If True, augment the training set to balance classes (1000 samples/class).\n",
                "        \n",
                "    Returns:\n",
                "        tuple: (train_df, val_df, test_df, class_names)\n",
                "               Each df has columns ['filepath', 'category', 'label', 'label_str']\n",
                "               class_names: list of string labels indexed by the label integer.\n",
                "    \"\"\"\n",
                "    if sum(split_ratios) != 1.0:\n",
                "        raise ValueError(\"Split ratios must sum to 1.0\")\n",
                "        \n",
                "    train_ratio, val_ratio, test_ratio = split_ratios\n",
                "    \n",
                "    # 1. Collect all data and identify classes\n",
                "    data = []\n",
                "    \n",
                "    # Get all categories (subdirectories in data_dir)\n",
                "    if target_category:\n",
                "        if not os.path.isdir(os.path.join(data_dir, target_category)):\n",
                "            raise ValueError(f\"Category '{target_category}' not found in {data_dir}\")\n",
                "        categories = [target_category]\n",
                "    else:\n",
                "        categories = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
                "        categories.sort() # Ensure deterministic order\n",
                "    \n",
                "    # First pass: Collect all unique label strings to build mapping\n",
                "    # We need to scan to find all defect types\n",
                "    unique_labels = set()\n",
                "    \n",
                "    for category in categories:\n",
                "        cat_dir = os.path.join(data_dir, category)\n",
                "        \n",
                "        # Train data (only 'good')\n",
                "        unique_labels.add(f\"{category}_good\")\n",
                "        \n",
                "        # Test data (contains 'good' and various defect types)\n",
                "        test_dir = os.path.join(cat_dir, 'test')\n",
                "        if os.path.exists(test_dir):\n",
                "            for defect_type in os.listdir(test_dir):\n",
                "                if os.path.isdir(os.path.join(test_dir, defect_type)):\n",
                "                    unique_labels.add(f\"{category}_{defect_type}\")\n",
                "                    \n",
                "    # Create class mapping\n",
                "    class_names = sorted(list(unique_labels))\n",
                "    class_to_idx = {name: i for i, name in enumerate(class_names)}\n",
                "    \n",
                "    logger.info(f\"Found {len(class_names)} unique classes: {class_names}\")\n",
                "    \n",
                "    # Second pass: Collect data with labels\n",
                "    for category in categories:\n",
                "        cat_dir = os.path.join(data_dir, category)\n",
                "        \n",
                "        # Train data (only 'good' usually in MVTec AD train set)\n",
                "        train_good_dir = os.path.join(cat_dir, 'train', 'good')\n",
                "        if os.path.exists(train_good_dir):\n",
                "            label_str = f\"{category}_good\"\n",
                "            label = class_to_idx[label_str]\n",
                "            for img_path in glob.glob(os.path.join(train_good_dir, '*.png')):\n",
                "                data.append({\n",
                "                    'filepath': img_path,\n",
                "                    'category': category,\n",
                "                    'label': label,\n",
                "                    'label_str': label_str\n",
                "                })\n",
                "                \n",
                "        # Test data (contains 'good' and various defect types)\n",
                "        test_dir = os.path.join(cat_dir, 'test')\n",
                "        if os.path.exists(test_dir):\n",
                "            for defect_type in os.listdir(test_dir):\n",
                "                defect_dir = os.path.join(test_dir, defect_type)\n",
                "                if not os.path.isdir(defect_dir):\n",
                "                    continue\n",
                "                    \n",
                "                label_str = f\"{category}_{defect_type}\"\n",
                "                label = class_to_idx[label_str]\n",
                "                \n",
                "                for img_path in glob.glob(os.path.join(defect_dir, '*.png')):\n",
                "                    data.append({\n",
                "                        'filepath': img_path,\n",
                "                        'category': category,\n",
                "                        'label': label,\n",
                "                        'label_str': label_str\n",
                "                    })\n",
                "\n",
                "    df = pd.DataFrame(data)\n",
                "    \n",
                "    if df.empty:\n",
                "        logger.warning(f\"No data found in {data_dir}\")\n",
                "        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), []\n",
                "\n",
                "    # 2. Stratified Split\n",
                "    # We want to stratify by Label (which now encodes both Category and DefectType)\n",
                "    # However, some defect types might have very few samples (e.g. < 3), which makes stratification impossible.\n",
                "    # We should fall back to simple random split or warn if stratification fails.\n",
                "    \n",
                "    # Check class counts\n",
                "    class_counts = df['label'].value_counts()\n",
                "    rare_classes = class_counts[class_counts < 2].index.tolist()\n",
                "    \n",
                "    if rare_classes:\n",
                "        logger.warning(f\"Classes {rare_classes} have fewer than 2 samples. Stratification for these will fail/be imperfect.\")\n",
                "        # For now, we proceed. train_test_split might error if a class has only 1 sample.\n",
                "        # We can filter out single-sample classes or just duplicate them? \n",
                "        # Let's assume MVTec AD has enough samples per defect type (usually > 10).\n",
                "    \n",
                "    # First split: Train vs (Val + Test)\n",
                "    test_val_ratio = val_ratio + test_ratio\n",
                "    \n",
                "    if test_val_ratio == 0:\n",
                "        return df, pd.DataFrame(), pd.DataFrame(), class_names\n",
                "        \n",
                "    try:\n",
                "        train_df, temp_df = train_test_split(\n",
                "            df, \n",
                "            train_size=train_ratio, \n",
                "            stratify=df['label'], \n",
                "            random_state=seed\n",
                "        )\n",
                "    except ValueError as e:\n",
                "        logger.warning(f\"Stratified split failed (likely due to rare classes): {e}. Falling back to random split.\")\n",
                "        train_df, temp_df = train_test_split(\n",
                "            df, \n",
                "            train_size=train_ratio, \n",
                "            random_state=seed\n",
                "        )\n",
                "\n",
                "    # 3. Augmentation (Balance Classes) - ONLY on Train set\n",
                "    if augment:\n",
                "        train_df = balance_classes(train_df, target_count=1000)\n",
                "    \n",
                "    # Second split: Val vs Test\n",
                "    if test_ratio == 0:\n",
                "        val_df = temp_df\n",
                "        test_df = pd.DataFrame()\n",
                "    elif val_ratio == 0:\n",
                "        val_df = pd.DataFrame()\n",
                "        test_df = temp_df\n",
                "    else:\n",
                "        relative_test_size = test_ratio / (val_ratio + test_ratio)\n",
                "        try:\n",
                "            val_df, test_df = train_test_split(\n",
                "                temp_df,\n",
                "                test_size=relative_test_size,\n",
                "                stratify=temp_df['label'],\n",
                "                random_state=seed\n",
                "            )\n",
                "        except ValueError:\n",
                "             val_df, test_df = train_test_split(\n",
                "                temp_df,\n",
                "                test_size=relative_test_size,\n",
                "                random_state=seed\n",
                "            )\n",
                "        \n",
                "    logger.info(f\"Data split complete.\")\n",
                "    logger.info(f\"Train: {len(train_df)} images\")\n",
                "    logger.info(f\"Val: {len(val_df)} images\")\n",
                "    logger.info(f\"Test: {len(test_df)} images\")\n",
                "    \n",
                "    return train_df, val_df, test_df, class_names\n",
                "\n",
                "# Hyperparameters\n",
                "IMG_SIZE = (256, 256)\n",
                "BATCH_SIZE = 16\n",
                "DATA_DIR = \"../data/raw\"\n",
                "TARGET_CATEGORY = 'bottle' # Train only on this category\n",
                "\n",
                "# Load data\n",
                "print(f\"Loading and splitting data for {TARGET_CATEGORY}...\")\n",
                "train_df, val_df, test_df, class_names = load_and_split_data(DATA_DIR, target_category=TARGET_CATEGORY, augment=True)\n",
                "\n",
                "# Filter for normal samples only for Autoencoder training\n",
                "print(\"Filtering for normal samples...\")\n",
                "normal_train_df = train_df[train_df['label_str'].str.endswith('_good')]\n",
                "print(f\"Normal training samples: {len(normal_train_df)}\")\n",
                "\n",
                "# Dataset creation helper\n",
                "def process_path(filepath):\n",
                "    img = tf.io.read_file(filepath)\n",
                "    img = tf.io.decode_image(img, channels=3, expand_animations=False)\n",
                "    img = tf.image.resize(img, IMG_SIZE)\n",
                "    # Rescale to [0, 1]\n",
                "    img = tf.cast(img, tf.float32) / 255.0\n",
                "    return img\n",
                "\n",
                "def create_dataset(dataframe, batch_size=16, shuffle=False):\n",
                "    filepaths = dataframe['filepath'].values\n",
                "    # Autoencoder doesn't need labels for training, but we need them for evaluation\n",
                "    # For training, we can just return images\n",
                "    ds = tf.data.Dataset.from_tensor_slices(filepaths)\n",
                "    ds = ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
                "    \n",
                "    if shuffle:\n",
                "        ds = ds.shuffle(buffer_size=1000)\n",
                "    \n",
                "    # Autoencoder expects (x, x)\n",
                "    ds = ds.map(lambda x: (x, x))\n",
                "    \n",
                "    ds = ds.batch(batch_size)\n",
                "    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
                "    return ds\n",
                "\n",
                "AUTOTUNE = tf.data.AUTOTUNE\n",
                "train_ds = create_dataset(normal_train_df, BATCH_SIZE, shuffle=True)\n",
                "# We can use val_df (filtered) for validation if we want\n",
                "normal_val_df = val_df[val_df['label_str'].str.endswith('_good')]\n",
                "val_ds = create_dataset(normal_val_df, BATCH_SIZE, shuffle=False)\n",
                "\n",
                "print(\"Datasets created.\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "931cff80",
            "metadata": {},
            "source": [
                "## 2. Model Architecture\n",
                "Encoder-Decoder architecture."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c95bdcb6",
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_autoencoder(input_shape):\n",
                "    # Encoder\n",
                "    inputs = layers.Input(shape=input_shape)\n",
                "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same', strides=2)(inputs)\n",
                "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', strides=2)(x)\n",
                "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', strides=2)(x)\n",
                "    \n",
                "    # Latent space\n",
                "    shape_before_flattening = tf.keras.backend.int_shape(x)[1:]\n",
                "    x = layers.Flatten()(x)\n",
                "    latent = layers.Dense(128, name='latent_vector')(x)\n",
                "    \n",
                "    # Decoder\n",
                "    x = layers.Dense(np.prod(shape_before_flattening))(latent)\n",
                "    x = layers.Reshape(shape_before_flattening)(x)\n",
                "    \n",
                "    x = layers.Conv2DTranspose(128, (3, 3), activation='relu', padding='same', strides=2)(x)\n",
                "    x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same', strides=2)(x)\n",
                "    x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same', strides=2)(x)\n",
                "    \n",
                "    outputs = layers.Conv2DTranspose(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
                "    \n",
                "    model = models.Model(inputs, outputs, name='autoencoder')\n",
                "    return model\n",
                "\n",
                "autoencoder = create_autoencoder(IMG_SIZE + (3,))\n",
                "autoencoder.summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b28e0cfc",
            "metadata": {},
            "source": [
                "## 3. Training\n",
                "Loss function is Mean Squared Error (MSE) between input and output."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "978ac196",
            "metadata": {},
            "outputs": [],
            "source": [
                "autoencoder.compile(optimizer='adam', loss='mse')\n",
                "\n",
                "history = autoencoder.fit(\n",
                "    train_ds,\n",
                "    epochs=20,\n",
                "    # In unsupervised setting, we often use a split of train set as validation,\n",
                "    # or just monitor loss.\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "17b6c377",
            "metadata": {},
            "source": [
                "# Create Test Dataset (with labels for evaluation)\n",
                "def process_path_label(filepath, label):\n",
                "    img = tf.io.read_file(filepath)\n",
                "    img = tf.io.decode_image(img, channels=3, expand_animations=False)\n",
                "    img = tf.image.resize(img, IMG_SIZE)\n",
                "    img = tf.cast(img, tf.float32) / 255.0\n",
                "    return img, label\n",
                "\n",
                "def create_test_dataset(dataframe):\n",
                "    filepaths = dataframe['filepath'].values\n",
                "    labels = dataframe['label'].values\n",
                "    ds = tf.data.Dataset.from_tensor_slices((filepaths, labels))\n",
                "    ds = ds.map(process_path_label, num_parallel_calls=AUTOTUNE)\n",
                "    ds = ds.batch(1) # Batch size 1 for individual prediction\n",
                "    return ds\n",
                "\n",
                "test_ds = create_test_dataset(test_df)\n",
                "\n",
                "def predict_anomaly(model, dataset, threshold=None):\n",
                "    reconstruction_errors = []\n",
                "    labels = []\n",
                "    \n",
                "    for image, label in dataset:\n",
                "        reconstructed = model.predict(image, verbose=0)\n",
                "        loss = np.mean(np.abs(image - reconstructed))\n",
                "        reconstruction_errors.append(loss)\n",
                "        labels.append(label.numpy()[0])\n",
                "        \n",
                "    return np.array(reconstruction_errors), np.array(labels)\n",
                "\n",
                "print(\"Predicting anomalies on test set...\")\n",
                "errors, labels = predict_anomaly(autoencoder, test_ds)\n",
                "\n",
                "# Determine threshold (e.g., 90th percentile of errors)\n",
                "threshold = np.percentile(errors, 90)\n",
                "print(f\"Threshold: {threshold}\")\n",
                "\n",
                "# Visualize\n",
                "plt.figure(figsize=(10, 5))\n",
                "# Identify normal label indices\n",
                "# We need to know which integer labels correspond to 'good'\n",
                "# class_names list has the strings.\n",
                "normal_indices = [i for i, name in enumerate(class_names) if name.endswith('_good')]\n",
                "\n",
                "# Create mask for normal and anomaly\n",
                "is_normal = np.isin(labels, normal_indices)\n",
                "\n",
                "plt.hist(errors[is_normal], bins=20, alpha=0.5, label='Normal')\n",
                "plt.hist(errors[~is_normal], bins=20, alpha=0.5, label='Anomaly')\n",
                "plt.axvline(threshold, color='r', linestyle='--', label='Threshold')\n",
                "plt.legend()\n",
                "plt.title(\"Reconstruction Error Distribution\")\n",
                "plt.show()"
            ],
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "15e236d4",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load Test Data\n",
                "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
                "    TEST_DIR,\n",
                "    label_mode='int',\n",
                "    image_size=IMG_SIZE,\n",
                "    batch_size=1,\n",
                "    shuffle=False\n",
                ")\n",
                "\n",
                "def predict_anomaly(model, dataset, threshold=None):\n",
                "    reconstruction_errors = []\n",
                "    labels = []\n",
                "    \n",
                "    for image, label in dataset:\n",
                "        image = preprocess(image)\n",
                "        reconstructed = model.predict(image, verbose=0)\n",
                "        loss = np.mean(np.abs(image - reconstructed))\n",
                "        reconstruction_errors.append(loss)\n",
                "        labels.append(label.numpy()[0])\n",
                "        \n",
                "    return np.array(reconstruction_errors), np.array(labels)\n",
                "\n",
                "errors, labels = predict_anomaly(autoencoder, test_ds)\n",
                "\n",
                "# Determine threshold (e.g., 95th percentile of errors)\n",
                "# Ideally this is done on a validation set of normal images\n",
                "threshold = np.percentile(errors, 90)\n",
                "print(f\"Threshold: {threshold}\")\n",
                "\n",
                "# Visualize\n",
                "plt.figure(figsize=(10, 5))\n",
                "plt.hist(errors[labels==0], bins=20, alpha=0.5, label='Normal')\n",
                "plt.hist(errors[labels!=0], bins=20, alpha=0.5, label='Anomaly')\n",
                "plt.axvline(threshold, color='r', linestyle='--', label='Threshold')\n",
                "plt.legend()\n",
                "plt.title(\"Reconstruction Error Distribution\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Advanced Evaluation for Autoencoder\n",
                "import numpy as np\n",
                "\n",
                "print(\"Evaluating Autoencoder...\")\n",
                "\n",
                "# 1. Calculate Reconstruction Error (MSE) for all test images\n",
                "reconstructions = autoencoder.predict(test_ds)\n",
                "mse_scores = []\n",
                "y_true_labels = []\n",
                "\n",
                "# We need to iterate through test_ds to get original images and labels\n",
                "# Note: test_ds yields (images, labels)\n",
                "idx = 0\n",
                "for images, labels in test_ds:\n",
                "    batch_recon = reconstructions[idx : idx + len(images)]\n",
                "    batch_mse = np.mean(np.square(images - batch_recon), axis=(1, 2, 3))\n",
                "    mse_scores.extend(batch_mse)\n",
                "    y_true_labels.extend(labels.numpy())\n",
                "    idx += len(images)\n",
                "\n",
                "mse_scores = np.array(mse_scores)\n",
                "y_true_labels = np.array(y_true_labels)\n",
                "\n",
                "# 2. Calculate AUC-ROC using MSE as anomaly score\n",
                "# Note: Higher MSE = Anomaly (1), Lower MSE = Normal (0)\n",
                "# Ensure labels are 0 (Normal) and 1 (Anomaly)\n",
                "auc = calculate_auc(y_true_labels, mse_scores)\n",
                "print(f\"AUC-ROC: {auc:.4f}\")\n",
                "\n",
                "# 3. Calculate F1-Score (requires thresholding)\n",
                "# Simple strategy: use mean + 2*std of normal samples from validation set as threshold\n",
                "# For now, we'll just pick a threshold that maximizes F1 on test set for demonstration\n",
                "best_f1 = 0\n",
                "best_thresh = 0\n",
                "thresholds = np.linspace(mse_scores.min(), mse_scores.max(), 100)\n",
                "\n",
                "for thresh in thresholds:\n",
                "    y_pred_bin = (mse_scores > thresh).astype(int)\n",
                "    f1 = calculate_f1(y_true_labels, y_pred_bin)\n",
                "    if f1 > best_f1:\n",
                "        best_f1 = f1\n",
                "        best_thresh = thresh\n",
                "\n",
                "print(f\"Best F1-Score: {best_f1:.4f} (at threshold {best_thresh:.4f})\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}