{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 02. Baseline CNN Model\n",
                "\n",
                "## Introduction\n",
                "This notebook implements a custom Convolutional Neural Network (CNN) from scratch for anomaly detection. \n",
                "It is fully self-contained and includes:\n",
                "1. Data Loading & Preprocessing\n",
                "2. Model Architecture Definition\n",
                "3. Training Loop\n",
                "4. Evaluation\n",
                "\n",
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras import layers, models, regularizers\n",
                "from sklearn.metrics import classification_report, confusion_matrix\n",
                "import seaborn as sns\n",
                "\n",
                "# Set random seed for reproducibility\n",
                "tf.random.set_seed(42)\n",
                "np.random.seed(42)\n",
                "\n",
                "print(f\"TensorFlow Version: {tf.__version__}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Configuration & Data Loading\n",
                "We define hyperparameters and load the dataset directly from the `data/raw` directory."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Hyperparameters\n",
                "IMG_HEIGHT = 256\n",
                "IMG_WIDTH = 256\n",
                "BATCH_SIZE = 32\n",
                "EPOCHS = 20\n",
                "LEARNING_RATE = 0.001\n",
                "DATA_DIR = \"../data/raw\"\n",
                "\n",
                "# For this baseline, we will treat 'good' as class 0 and all other defects as class 1 (Binary Classification)\n",
                "# Or we can do multi-class if we want to classify defect types.\n",
                "# Let's stick to a simple Binary Classification (Normal vs Anomaly) per category for simplicity in this demo,\n",
                "# OR a global multi-class classification if we mix all categories.\n",
                "# Given MVTec structure, usually models are trained PER CATEGORY.\n",
                "# Here, we will demonstrate training on ONE category (e.g., 'bottle') to keep it runnable.\n",
                "\n",
                "TARGET_CATEGORY = 'bottle'\n",
                "TRAIN_DIR = os.path.join(DATA_DIR, TARGET_CATEGORY, 'train')\n",
                "TEST_DIR = os.path.join(DATA_DIR, TARGET_CATEGORY, 'test')\n",
                "\n",
                "print(f\"Training on category: {TARGET_CATEGORY}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_data(category_path, img_size, batch_size, subset='train'):\n",
                "    # Custom data loader generator could be used here, but for simplicity we use image_dataset_from_directory\n",
                "    # Note: MVTec 'train' only has 'good'. 'test' has 'good' and defects.\n",
                "    # To train a supervised classifier, we need anomalies in training or use outlier detection.\n",
                "    # Since this is a \"Baseline CNN\" (Supervised), we technically need defective samples in train.\n",
                "    # MVTec is designed for Unsupervised/One-Class learning.\n",
                "    # HOWEVER, for the sake of this exercise (Baseline CNN), we will split the TEST set to get some anomalies for training,\n",
                "    # or we assume we are doing a multi-class classification of the defects provided in test.\n",
                "    \n",
                "    # Let's try to load the TEST set and split it into Train/Val for the purpose of supervised classification demonstration.\n",
                "    \n",
                "    print(f\"Loading data from {category_path}...\")\n",
                "    ds = tf.keras.utils.image_dataset_from_directory(\n",
                "        category_path,\n",
                "        seed=123,\n",
                "        image_size=img_size,\n",
                "        batch_size=batch_size,\n",
                "        label_mode='int' # Categorical labels (good, broken_large, etc.)\n",
                "    )\n",
                "    return ds\n",
                "\n",
                "# Load Test data (which contains all classes) and split it for this supervised demo\n",
                "full_ds = load_data(TEST_DIR, (IMG_HEIGHT, IMG_WIDTH), BATCH_SIZE)\n",
                "\n",
                "class_names = full_ds.class_names\n",
                "print(f\"Classes: {class_names}\")\n",
                "\n",
                "# Split into train/val (80/20)\n",
                "train_size = int(0.8 * len(full_ds))\n",
                "train_ds = full_ds.take(train_size)\n",
                "val_ds = full_ds.skip(train_size)\n",
                "\n",
                "# Performance optimization\n",
                "AUTOTUNE = tf.data.AUTOTUNE\n",
                "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
                "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Model Architecture\n",
                "We define a custom CNN with Convolutional blocks, Batch Normalization, and Dropout."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_cnn_custom(input_shape, num_classes):\n",
                "    inputs = layers.Input(shape=input_shape)\n",
                "    \n",
                "    # Rescaling [0, 255] -> [0, 1]\n",
                "    x = layers.Rescaling(1./255)(inputs)\n",
                "    \n",
                "    # Block 1\n",
                "    x = layers.Conv2D(32, 3, padding='same')(x)\n",
                "    x = layers.BatchNormalization()(x)\n",
                "    x = layers.Activation('relu')(x)\n",
                "    x = layers.MaxPooling2D()(x)\n",
                "    \n",
                "    # Block 2\n",
                "    x = layers.Conv2D(64, 3, padding='same')(x)\n",
                "    x = layers.BatchNormalization()(x)\n",
                "    x = layers.Activation('relu')(x)\n",
                "    x = layers.MaxPooling2D()(x)\n",
                "    \n",
                "    # Block 3\n",
                "    x = layers.Conv2D(128, 3, padding='same')(x)\n",
                "    x = layers.BatchNormalization()(x)\n",
                "    x = layers.Activation('relu')(x)\n",
                "    x = layers.MaxPooling2D()(x)\n",
                "    \n",
                "    # Dense\n",
                "    x = layers.GlobalAveragePooling2D()(x)\n",
                "    x = layers.Dense(128, kernel_regularizer=regularizers.l2(0.01))(x)\n",
                "    x = layers.Activation('relu')(x)\n",
                "    x = layers.Dropout(0.5)(x)\n",
                "    \n",
                "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
                "    \n",
                "    model = models.Model(inputs, outputs, name=\"cnn_custom\")\n",
                "    return model\n",
                "\n",
                "model = create_cnn_custom((IMG_HEIGHT, IMG_WIDTH, 3), len(class_names))\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Training\n",
                "We compile and train the model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.compile(\n",
                "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
                "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
                "    metrics=['accuracy']\n",
                ")\n",
                "\n",
                "history = model.fit(\n",
                "    train_ds,\n",
                "    validation_data=val_ds,\n",
                "    epochs=EPOCHS,\n",
                "    callbacks=[\n",
                "        tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
                "        tf.keras.callbacks.ReduceLROnPlateau(factor=0.2, patience=3)\n",
                "    ]\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Evaluation\n",
                "Visualizing loss curves and confusion matrix."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot History\n",
                "acc = history.history['accuracy']\n",
                "val_acc = history.history['val_accuracy']\n",
                "loss = history.history['loss']\n",
                "val_loss = history.history['val_loss']\n",
                "epochs_range = range(len(acc))\n",
                "\n",
                "plt.figure(figsize=(12, 4))\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
                "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
                "plt.legend(loc='lower right')\n",
                "plt.title('Accuracy')\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(epochs_range, loss, label='Training Loss')\n",
                "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
                "plt.legend(loc='upper right')\n",
                "plt.title('Loss')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confusion Matrix\n",
                "y_true = []\n",
                "y_pred = []\n",
                "\n",
                "for images, labels in val_ds:\n",
                "    preds = model.predict(images, verbose=0)\n",
                "    y_true.extend(labels.numpy())\n",
                "    y_pred.extend(np.argmax(preds, axis=1))\n",
                "\n",
                "cm = confusion_matrix(y_true, y_pred)\n",
                "plt.figure(figsize=(10, 8))\n",
                "sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names)\n",
                "plt.xlabel('Predicted')\n",
                "plt.ylabel('True')\n",
                "plt.title('Confusion Matrix')\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}