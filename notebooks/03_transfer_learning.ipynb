{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "f49d8bfe",
            "metadata": {},
            "source": [
                "# 03. Transfer Learning (ResNet50)\n",
                "\n",
                "## Introduction\n",
                "This notebook implements Transfer Learning using a pre-trained ResNet50 model.\n",
                "It is fully self-contained.\n",
                "\n",
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "c674749d",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-11-24 10:10:49.468598: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
                        "2025-11-24 10:10:49.636615: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
                        "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
                        "/home/mathieu/Works/Projet-PIC/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
                        "  warnings.warn(\n",
                        "/home/mathieu/Works/Projet-PIC/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
                        "  warnings.warn(\n",
                        "/home/mathieu/Works/Projet-PIC/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
                        "  warnings.warn(\n",
                        "/home/mathieu/Works/Projet-PIC/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
                        "  warnings.warn(\n",
                        "/home/mathieu/Works/Projet-PIC/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
                        "  warnings.warn(\n",
                        "/home/mathieu/Works/Projet-PIC/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
                        "  warnings.warn(\n",
                        "/home/mathieu/Works/Projet-PIC/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
                        "  warnings.warn(\n",
                        "/home/mathieu/Works/Projet-PIC/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
                        "  warnings.warn(\n",
                        "/home/mathieu/Works/Projet-PIC/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
                        "  warnings.warn(\n",
                        "/home/mathieu/Works/Projet-PIC/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
                        "  warnings.warn(\n",
                        "/home/mathieu/Works/Projet-PIC/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
                        "  warnings.warn(\n",
                        "/home/mathieu/Works/Projet-PIC/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
                        "  warnings.warn(\n",
                        "/home/mathieu/Works/Projet-PIC/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
                        "  warnings.warn(\n",
                        "/home/mathieu/Works/Projet-PIC/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
                        "  warnings.warn(\n",
                        "/home/mathieu/Works/Projet-PIC/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
                        "  warnings.warn(\n",
                        "/home/mathieu/Works/Projet-PIC/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
                        "  warnings.warn(\n",
                        "/home/mathieu/Works/Projet-PIC/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
                        "  warnings.warn(\n",
                        "/home/mathieu/Works/Projet-PIC/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
                        "  warnings.warn(\n",
                        "/home/mathieu/Works/Projet-PIC/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
                        "  warnings.warn(\n",
                        "/home/mathieu/Works/Projet-PIC/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
                        "  warnings.warn(\n",
                        "2025-11-24 10:10:53.246618: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras import layers, models\n",
                "from tensorflow.keras.applications import ResNet50\n",
                "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
                "\n",
                "tf.random.set_seed(42)\n",
                "np.random.seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "25ed511c",
            "metadata": {},
            "source": [
                "## 1. Data Loading\n",
                "Using the same strategy as the baseline: training on the multi-class data from the test folder for demonstration."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "a30c48ab",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading and splitting data for capsule...\n",
                        "Classes: ['capsule_crack', 'capsule_faulty_imprint', 'capsule_good', 'capsule_poke', 'capsule_scratch', 'capsule_squeeze']\n",
                        "Number of classes: 6\n",
                        "Datasets created and preprocessed.\n"
                    ]
                }
            ],
            "source": [
                "import sys\nimport os\nimport glob\nimport pandas as pd\nimport random\nimport shutil\nimport logging\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score, f1_score, confusion_matrix\nfrom skimage import measure\n\n# --- Inlined from src.evaluation.metrics ---\n\ndef get_metrics():\n    \"\"\"\n    Returns a list of Keras metrics.\n    \"\"\"\n    return [\n        tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy'),\n    ]\n\ndef calculate_auc(y_true, y_pred):\n    \"\"\"\n    Calculate AUC-ROC score.\n    \"\"\"\n    # For multi-class, we might need one-vs-rest\n    if len(np.unique(y_true)) > 2:\n        return roc_auc_score(y_true, y_pred, multi_class='ovr')\n    return roc_auc_score(y_true, y_pred)\n\ndef calculate_f1(y_true, y_pred_classes):\n    \"\"\"\n    Calculate F1 score.\n    \"\"\"\n    return f1_score(y_true, y_pred_classes, average='macro')\n\ndef get_confusion_matrix(y_true, y_pred_classes):\n    \"\"\"\n    Calculate confusion matrix.\n    \"\"\"\n    return confusion_matrix(y_true, y_pred_classes)\n\ndef calculate_iou(y_true, y_pred, threshold=0.5):\n    \"\"\"\n    Calculate Intersection over Union (IoU) for segmentation masks.\n    y_true: Ground truth masks (0 or 1)\n    y_pred: Predicted anomaly maps (0 to 1)\n    \"\"\"\n    y_pred_bin = (y_pred > threshold).astype(int)\n    y_true = y_true.astype(int)\n    \n    intersection = np.logical_and(y_true, y_pred_bin).sum()\n    union = np.logical_or(y_true, y_pred_bin).sum()\n    \n    if union == 0:\n        return 1.0 if intersection == 0 else 0.0\n        \n    return intersection / union\n\ndef calculate_pro(y_true, y_pred, threshold=0.5):\n    \"\"\"\n    Calculate Per-Region Overlap (PRO).\n    Average coverage of each connected component in ground truth.\n    \"\"\"\n    y_pred_bin = (y_pred > threshold).astype(int)\n    y_true = y_true.astype(int)\n    \n    # Label connected components in ground truth\n    labeled_gt, num_features = measure.label(y_true, return_num=True, connectivity=2)\n    \n    if num_features == 0:\n        # No anomalies in ground truth\n        # If prediction is also empty, perfect. If prediction has noise, it's a false positive.\n        # PRO is typically defined on anomalous regions. \n        # We return 1.0 if no anomalies exist (perfect coverage of \"nothing\").\n        return 1.0\n        \n    pro_scores = []\n    for region_idx in range(1, num_features + 1):\n        region_mask = (labeled_gt == region_idx)\n        region_area = region_mask.sum()\n        \n        # Intersection of prediction with this region\n        intersection = np.logical_and(region_mask, y_pred_bin).sum()\n        \n        coverage = intersection / region_area\n        pro_scores.append(coverage)\n        \n    return np.mean(pro_scores)\n\n# --- Inlined from src.evaluation.benchmark ---\n\nlogger = logging.getLogger(__name__)\n\ndef evaluate_model(model, test_dataset, test_masks=None):\n    \"\"\"\n    Evaluates a model on the test dataset.\n    \"\"\"\n    logger.info(\"Evaluating model...\")\n    results = model.evaluate(test_dataset, return_dict=True)\n    \n    # Get predictions for advanced metrics\n    y_true = []\n    y_pred = []\n    \n    for images, labels in test_dataset:\n        preds = model.predict(images, verbose=0)\n        y_true.extend(labels.numpy())\n        y_pred.extend(preds)\n        \n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n    y_pred_classes = np.argmax(y_pred, axis=1)\n    \n    # Calculate additional metrics\n    try:\n        auc = calculate_auc(y_true, y_pred) # Might fail if only one class in batch\n        f1 = calculate_f1(y_true, y_pred_classes)\n        results['auc'] = auc\n        results['f1'] = f1\n        \n        if test_masks is not None:\n            # Assuming test_masks matches y_pred order\n            # We need to ensure y_pred is in the same shape/format as masks if they are images\n            # But y_pred from classification model is (N, num_classes) or (N, 1)\n            # IoU/PRO require segmentation maps (N, H, W, 1)\n            # If the model is an Autoencoder, we might generate maps.\n            # If it's a classifier, IoU/PRO don't make sense unless we have CAM/GradCAM.\n            \n            # For now, we only calculate if we have compatible shapes\n            if len(y_pred.shape) == 4 and len(test_masks.shape) == 4:\n                 iou = calculate_iou(test_masks, y_pred)\n                 pro = calculate_pro(test_masks, y_pred)\n                 results['iou'] = iou\n                 results['pro'] = pro\n            else:\n                logger.warning(\"Skipping IoU/PRO: Predictions or masks shape mismatch for segmentation.\")\n    except Exception as e:\n        logger.warning(f\"Could not calculate advanced metrics: {e}\")\n        \n    return results\n\ndef compare_models(models_dict, test_dataset):\n    \"\"\"\n    Compares multiple models.\n    \"\"\"\n    comparison = {}\n    for name, model in models_dict.items():\n        logger.info(f\"Benchmarking {name}...\")\n        comparison[name] = evaluate_model(model, test_dataset)\n        \n    return comparison\n\n# --- Inlined from src.preprocessing.dataset ---\n\ndef augment_image(image_path, save_dir, prefix, count):\n    \"\"\"\n    Reads an image, applies random augmentations, and saves it.\n    \"\"\"\n    try:\n        img = tf.io.read_file(image_path)\n        img = tf.image.decode_png(img, channels=3)\n        \n        # Random augmentations\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_flip_up_down(img)\n        img = tf.image.random_brightness(img, max_delta=0.2)\n        img = tf.image.random_contrast(img, lower=0.8, upper=1.2)\n        \n        # Ensure valid range [0, 255]\n        img = tf.clip_by_value(img, 0, 255)\n        img = tf.cast(img, tf.uint8)\n        \n        encoded_img = tf.image.encode_png(img)\n        \n        filename = f\"{prefix}_{count}.png\"\n        save_path = os.path.join(save_dir, filename)\n        \n        tf.io.write_file(save_path, encoded_img)\n        return save_path\n    except Exception as e:\n        logger.warning(f\"Failed to augment image {image_path}: {e}\")\n        return None\n\ndef balance_classes(df, target_count=1000, save_root=\"data/processed/augmented\"):\n    \"\"\"\n    Balances classes in the DataFrame by augmenting rare classes to reach target_count.\n    \"\"\"\n    if df.empty:\n        return df\n        \n    logger.info(f\"Balancing classes to target count: {target_count}...\")\n    \n    # Create augmentation directory\n    if os.path.exists(save_root):\n        # Optional: Clear previous augmentations to avoid staleness, \n        # but might be slow if we re-run often. For now, let's keep it simple and overwrite/add.\n        pass\n    else:\n        os.makedirs(save_root, exist_ok=True)\n        \n    new_rows = []\n    \n    # Group by label (which maps to a specific Category_DefectType)\n    # We need to know the label_str to name files appropriately\n    unique_labels = df['label'].unique()\n    \n    for label in unique_labels:\n        class_subset = df[df['label'] == label]\n        current_count = len(class_subset)\n        \n        if current_count >= target_count:\n            continue\n            \n        needed = target_count - current_count\n        label_str = class_subset.iloc[0]['label_str']\n        category = class_subset.iloc[0]['category']\n        \n        logger.info(f\"Augmenting class '{label_str}': {current_count} -> {target_count} (+{needed})\")\n        \n        # Create class specific save dir\n        class_save_dir = os.path.join(save_root, label_str)\n        os.makedirs(class_save_dir, exist_ok=True)\n        \n        # Source images to augment\n        source_images = class_subset['filepath'].tolist()\n        \n        for i in range(needed):\n            # Randomly select a source image\n            src_img = random.choice(source_images)\n            \n            # Augment and save\n            new_path = augment_image(src_img, class_save_dir, \"aug\", i)\n            \n            if new_path:\n                new_rows.append({\n                    'filepath': new_path,\n                    'category': category,\n                    'label': label,\n                    'label_str': label_str\n                })\n                \n    if new_rows:\n        augmented_df = pd.DataFrame(new_rows)\n        df = pd.concat([df, augmented_df], ignore_index=True)\n        \n    logger.info(f\"Balancing complete. Total samples: {len(df)}\")\n    return df\n\ndef load_and_split_data(data_dir, split_ratios=(0.8, 0.1, 0.1), seed=42, target_category=None, augment=False):\n    \"\"\"\n    Load MVTec AD data, merge normal and abnormal, and split into train/val/test.\n    Assigns unique labels for each (Category, DefectType) pair.\n    \n    Args:\n        data_dir (str): Path to the root of the MVTec AD dataset (containing category folders).\n        split_ratios (tuple): (train_ratio, val_ratio, test_ratio). Must sum to 1.\n        seed (int): Random seed for reproducibility.\n        target_category (str, optional): If provided, only load data for this specific category.\n        augment (bool): If True, augment the training set to balance classes (1000 samples/class).\n        \n    Returns:\n        tuple: (train_df, val_df, test_df, class_names)\n               Each df has columns ['filepath', 'category', 'label', 'label_str']\n               class_names: list of string labels indexed by the label integer.\n    \"\"\"\n    if sum(split_ratios) != 1.0:\n        raise ValueError(\"Split ratios must sum to 1.0\")\n        \n    train_ratio, val_ratio, test_ratio = split_ratios\n    \n    # 1. Collect all data and identify classes\n    data = []\n    \n    # Get all categories (subdirectories in data_dir)\n    if target_category:\n        if not os.path.isdir(os.path.join(data_dir, target_category)):\n            raise ValueError(f\"Category '{target_category}' not found in {data_dir}\")\n        categories = [target_category]\n    else:\n        categories = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n        categories.sort() # Ensure deterministic order\n    \n    # First pass: Collect all unique label strings to build mapping\n    # We need to scan to find all defect types\n    unique_labels = set()\n    \n    for category in categories:\n        cat_dir = os.path.join(data_dir, category)\n        \n        # Train data (only 'good')\n        unique_labels.add(f\"{category}_good\")\n        \n        # Test data (contains 'good' and various defect types)\n        test_dir = os.path.join(cat_dir, 'test')\n        if os.path.exists(test_dir):\n            for defect_type in os.listdir(test_dir):\n                if os.path.isdir(os.path.join(test_dir, defect_type)):\n                    unique_labels.add(f\"{category}_{defect_type}\")\n                    \n    # Create class mapping\n    class_names = sorted(list(unique_labels))\n    class_to_idx = {name: i for i, name in enumerate(class_names)}\n    \n    logger.info(f\"Found {len(class_names)} unique classes: {class_names}\")\n    \n    # Second pass: Collect data with labels\n    for category in categories:\n        cat_dir = os.path.join(data_dir, category)\n        \n        # Train data (only 'good' usually in MVTec AD train set)\n        train_good_dir = os.path.join(cat_dir, 'train', 'good')\n        if os.path.exists(train_good_dir):\n            label_str = f\"{category}_good\"\n            label = class_to_idx[label_str]\n            for img_path in glob.glob(os.path.join(train_good_dir, '*.png')):\n                data.append({\n                    'filepath': img_path,\n                    'category': category,\n                    'label': label,\n                    'label_str': label_str\n                })\n                \n        # Test data (contains 'good' and various defect types)\n        test_dir = os.path.join(cat_dir, 'test')\n        if os.path.exists(test_dir):\n            for defect_type in os.listdir(test_dir):\n                defect_dir = os.path.join(test_dir, defect_type)\n                if not os.path.isdir(defect_dir):\n                    continue\n                    \n                label_str = f\"{category}_{defect_type}\"\n                label = class_to_idx[label_str]\n                \n                for img_path in glob.glob(os.path.join(defect_dir, '*.png')):\n                    data.append({\n                        'filepath': img_path,\n                        'category': category,\n                        'label': label,\n                        'label_str': label_str\n                    })\n\n    df = pd.DataFrame(data)\n    \n    if df.empty:\n        logger.warning(f\"No data found in {data_dir}\")\n        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), []\n\n    # 2. Stratified Split\n    # We want to stratify by Label (which now encodes both Category and DefectType)\n    # However, some defect types might have very few samples (e.g. < 3), which makes stratification impossible.\n    # We should fall back to simple random split or warn if stratification fails.\n    \n    # Check class counts\n    class_counts = df['label'].value_counts()\n    rare_classes = class_counts[class_counts < 2].index.tolist()\n    \n    if rare_classes:\n        logger.warning(f\"Classes {rare_classes} have fewer than 2 samples. Stratification for these will fail/be imperfect.\")\n        # For now, we proceed. train_test_split might error if a class has only 1 sample.\n        # We can filter out single-sample classes or just duplicate them? \n        # Let's assume MVTec AD has enough samples per defect type (usually > 10).\n    \n    # First split: Train vs (Val + Test)\n    test_val_ratio = val_ratio + test_ratio\n    \n    if test_val_ratio == 0:\n        return df, pd.DataFrame(), pd.DataFrame(), class_names\n        \n    try:\n        train_df, temp_df = train_test_split(\n            df, \n            train_size=train_ratio, \n            stratify=df['label'], \n            random_state=seed\n        )\n    except ValueError as e:\n        logger.warning(f\"Stratified split failed (likely due to rare classes): {e}. Falling back to random split.\")\n        train_df, temp_df = train_test_split(\n            df, \n            train_size=train_ratio, \n            random_state=seed\n        )\n\n    # 3. Augmentation (Balance Classes) - ONLY on Train set\n    if augment:\n        train_df = balance_classes(train_df, target_count=1000)\n    \n    # Second split: Val vs Test\n    if test_ratio == 0:\n        val_df = temp_df\n        test_df = pd.DataFrame()\n    elif val_ratio == 0:\n        val_df = pd.DataFrame()\n        test_df = temp_df\n    else:\n        relative_test_size = test_ratio / (val_ratio + test_ratio)\n        try:\n            val_df, test_df = train_test_split(\n                temp_df,\n                test_size=relative_test_size,\n                stratify=temp_df['label'],\n                random_state=seed\n            )\n        except ValueError:\n             val_df, test_df = train_test_split(\n                temp_df,\n                test_size=relative_test_size,\n                random_state=seed\n            )\n        \n    logger.info(f\"Data split complete.\")\n    logger.info(f\"Train: {len(train_df)} images\")\n    logger.info(f\"Val: {len(val_df)} images\")\n    logger.info(f\"Test: {len(test_df)} images\")\n    \n    return train_df, val_df, test_df, class_names\n",
                "\n",
                "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
                "\n",
                "IMG_SIZE = (256, 256)\n",
                "BATCH_SIZE = 32\n",
                "DATA_DIR = \"../data/raw\"\n",
                "TARGET_CATEGORY = 'capsule' # Train only on this category\n",
                "\n",
                "# Load data\n",
                "print(f\"Loading and splitting data for {TARGET_CATEGORY}...\")\n",
                "train_df, val_df, test_df, class_names = load_and_split_data(DATA_DIR, target_category=TARGET_CATEGORY, augment=True)\n",
                "num_classes = len(class_names)\n",
                "\n",
                "print(f\"Classes: {class_names}\")\n",
                "print(f\"Number of classes: {num_classes}\")\n",
                "\n",
                "# Dataset creation helper\n",
                "def process_path(filepath, label):\n",
                "    img = tf.io.read_file(filepath)\n",
                "    img = tf.io.decode_image(img, channels=3, expand_animations=False)\n",
                "    img = tf.image.resize(img, IMG_SIZE)\n",
                "    return img, label\n",
                "\n",
                "def create_dataset(dataframe, batch_size=32, shuffle=False):\n",
                "    filepaths = dataframe['filepath'].values\n",
                "    labels = dataframe['label'].values\n",
                "    ds = tf.data.Dataset.from_tensor_slices((filepaths, labels))\n",
                "    ds = ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
                "    if shuffle:\n",
                "        ds = ds.shuffle(buffer_size=1000)\n",
                "    ds = ds.batch(batch_size)\n",
                "    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
                "    return ds\n",
                "\n",
                "AUTOTUNE = tf.data.AUTOTUNE\n",
                "\n",
                "# Create base datasets\n",
                "train_ds = create_dataset(train_df, BATCH_SIZE, shuffle=True)\n",
                "val_ds = create_dataset(val_df, BATCH_SIZE, shuffle=False)\n",
                "test_ds = create_dataset(test_df, BATCH_SIZE, shuffle=False)\n",
                "\n",
                "# Apply ResNet preprocessing\n",
                "def preprocess_resnet(image, label):\n",
                "    return preprocess_input(image), label\n",
                "\n",
                "train_ds = train_ds.map(preprocess_resnet, num_parallel_calls=AUTOTUNE)\n",
                "val_ds = val_ds.map(preprocess_resnet, num_parallel_calls=AUTOTUNE)\n",
                "test_ds = test_ds.map(preprocess_resnet, num_parallel_calls=AUTOTUNE)\n",
                "\n",
                "print(\"Datasets created and preprocessed.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4aa85aee",
            "metadata": {},
            "source": [
                "## 2. Model Definition\n",
                "We load ResNet50 (ImageNet weights), freeze the base, and add a custom classification head."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "22f8e12c",
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_resnet_model(input_shape, num_classes):\n",
                "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
                "    \n",
                "    # Freeze base model\n",
                "    base_model.trainable = False\n",
                "    \n",
                "    inputs = tf.keras.Input(shape=input_shape)\n",
                "    x = base_model(inputs, training=False)\n",
                "    x = layers.GlobalAveragePooling2D()(x)\n",
                "    x = layers.Dense(256, activation='relu')(x)\n",
                "    x = layers.Dropout(0.5)(x)\n",
                "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
                "    \n",
                "    model = models.Model(inputs, outputs, name=\"resnet50_transfer\")\n",
                "    return model\n",
                "\n",
                "model = create_resnet_model(IMG_SIZE + (3,), num_classes)\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d40c3288",
            "metadata": {},
            "source": [
                "## 3. Training\n",
                "Training the top layers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dff26539",
            "metadata": {},
            "outputs": [],
            "source": [
                "model.compile(\n",
                "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
                "    loss='sparse_categorical_crossentropy',\n",
                "    metrics=['accuracy']\n",
                ")\n",
                "\n",
                "history = model.fit(\n",
                "    train_ds,\n",
                "    validation_data=val_ds,\n",
                "    epochs=10,\n",
                "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)]\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "41a32e79",
            "metadata": {},
            "source": [
                "## 4. Fine-tuning (Optional)\n",
                "Unfreezing the last few layers of ResNet for better performance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e16b02e8",
            "metadata": {},
            "outputs": [],
            "source": [
                "base_model = model.layers[1]\n",
                "base_model.trainable = True\n",
                "\n",
                "# Freeze all except last 20 layers\n",
                "for layer in base_model.layers[:-20]:\n",
                "    layer.trainable = False\n",
                "    \n",
                "model.compile(\n",
                "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), # Lower LR\n",
                "    loss='sparse_categorical_crossentropy',\n",
                "    metrics=['accuracy']\n",
                ")\n",
                "\n",
                "history_fine = model.fit(\n",
                "    train_ds,\n",
                "    validation_data=val_ds,\n",
                "    epochs=10,\n",
                "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Advanced Evaluation\n",
                "\n",
                "print(\"Evaluating model with advanced metrics...\")\n",
                "results = evaluate_model(model, test_ds)\n",
                "\n",
                "print(\"\\nEvaluation Results:\")\n",
                "for metric, value in results.items():\n",
                "    print(f\"{metric}: {value:.4f}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}